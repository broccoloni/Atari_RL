{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "645a43c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import ale_py as a\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from AtariNet import *\n",
    "from Atari_genetic import game_params,load_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dd3f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[print(i,j) for i,j in enumerate(gym.envs.registry.all())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "published-appearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = \"Tetris\"\n",
    "cur_gen = 2\n",
    "params = game_params(game)\n",
    "numactions = params[0]\n",
    "inshape = params[1]\n",
    "mut_power = params[2]\n",
    "test_size = params[3]\n",
    "poolsizes = params[4]\n",
    "numconvlayers = params[5]\n",
    "trunc = params[6]\n",
    "\n",
    "population,mutations,avg_rewards = load_gen(game,cur_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d57322bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version +a7a216c)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version +a7a216c)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "ale = a.ALEInterface()\n",
    "env = gym.make(f'ALE/{game}-v5')\n",
    "env = gym.wrappers.GrayScaleObservation(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "engaging-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = population[0]\n",
    "mut = mutations[0]\n",
    "torch.manual_seed(seed)\n",
    "atarinet = AtariNetCONV(inshape=inshape,\n",
    "                        poolsizes = poolsizes,\n",
    "                        numconvlayers = numconvlayers, \n",
    "                        outsize = numactions)\n",
    "\n",
    "atarinet.mutate(mut_power,mut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "attached-boston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267\n"
     ]
    }
   ],
   "source": [
    "for i_episode in range(1):\n",
    "    obs = env.reset()\n",
    "    prev_obs = np.zeros(obs.shape)\n",
    "    time.sleep(0.5)\n",
    "    for t in range(10000):\n",
    "        env.render()\n",
    "\n",
    "#         time.sleep(0.01)\n",
    "        \n",
    "        #Preprocessing\n",
    "        observation = ProcessIm_DemonAttack(obs,prev_obs)    \n",
    "\n",
    "        #Forward pass\n",
    "        probs = atarinet.forward(observation)\n",
    "\n",
    "        #Sample action space from probability distribution\n",
    "        action = np.random.choice(numactions, 1, p = probs.detach().numpy())[0]\n",
    "#         action = env.action_space.sample()\n",
    "#         actions = [i for i in range(numactions)]\n",
    "#         action = actions[i_episode]\n",
    "\n",
    "        #Take action\n",
    "        prev_obs = obs\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        if reward <0:\n",
    "            print(reward)\n",
    "        \n",
    "        \n",
    "#         plt.imshow(MaxPool(observation-new_observation),cmap = \"gray\")\n",
    "#         plt.show()\n",
    "#         print(reward,info['lives'], observation.shape)\n",
    "        if done:\n",
    "            print(t)\n",
    "            break\n",
    "# print(env.action_space)\n",
    "# print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dimensional-ocean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01705882352941176"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(avg_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-dispatch",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
